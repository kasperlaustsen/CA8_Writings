







The model derived in \cref{sec:mod_collec} is non-linear and thus not directly applicable for the control strategies intended for this project. Therefore a linearisation must be performed, where a linear approximation of the model is found at a given operating point. This will remove all non-linear dynamics of the model, facilitating the intended control strategies. It does however decrease model accuracy, especially when the system states are not near their respective operating points. All these issues will be touched upon in this section, as the linearisation is discussed.\\

A continuous linear state space system is typically defined as seen in \cref{eq:state_space}. The state derivatives are defined as a linear combination of states and inputs, while the outputs are a linear combination of the states. Having a model on such a state space form is a necessary for conventional state-space controller design.\\

\begin{equation} \label{eq:state_space}
	\begin{split}
		\dot{x} & = Ax + Bu + B_dd \\
		y 		& = Cx
	\end{split}
\end{equation}

where

\begin{center}
	\begin{tabular}{l p{8cm} l}
		$x$       & State vector                    &  \\
		$\dot{x}$ & Time derivative of state vector &  \\
		$y$       & Output vector                   &  \\
		$d$       & Disturbance vector              &  \\
		$A$       & System matrix                   &  \\
		$B$       & Controllable input matrix       &  \\
		$B_d$     & Disturbance input matrix        &  \\
		$C$       & Output matrix                   &
	\end{tabular}
\end{center}

To transform the non-linear model in \cref{eq:f_noSub} to this form, a first order Taylor expansion is used. Performing this method of linearisation will directly output the \textit{A}, \textit{B}, \textit{$B_d$} and \textit{C} matrices of the linear state space representation.\\

Consider some system $\dot{x} = f(x,u,d)$ with x a vector of system states, u a vector of controlled inputs, and d a vector of disturbances. Such a system can be approximated with a first order Taylor expansion at an operating point ($x_o, u_o, d_o$) as such:

\begin{equation} \label{eq:taylor}
	\dot{x}   \approx   f(x_o, u_o, d_o)   +
	\left. \dfrac{\partial f}{\partial x} \right |_{x_o, u_o, d_o} \cdot (x-x_0) +
	\left. \dfrac{\partial f}{\partial u} \right |_{x_o, u_o, d_o} \cdot (u-u_0) +
	\left. \dfrac{\partial f}{\partial d} \right |_{x_o, u_o, d_o} \cdot (d-d_0)
\end{equation}

The linearisation is done at an equilibrium point such that $f(x_o, u_o, d_o) = 0$ in \cref{eq:taylor}. The partial derivatives can be organized in Jacobian matrices on the form seen in \cref{eq:jacobians} where e is the number of state equations in the non linear system and nx, nu and nd being the number of states, inputs and disturbances respectively.

\begin{equation} \label{eq:jacobians}
	\dfrac{\partial f}{\partial x} =
		\begin{bmatrix}
			\dfrac{\partial f_1}{\partial x_1} & \cdots & \dfrac{\partial f_1}{\partial x_{nx}} & \\
			\vdots & \ddots & \vdots & \\
			\dfrac{\partial f_e}{\partial x_1} & \cdots & \dfrac{\partial f_e}{\partial x_{nx}} &
		\end{bmatrix}, \
	\dfrac{\partial f}{\partial u} =
		\begin{bmatrix}
			\dfrac{\partial f_1}{\partial u_1} & \cdots & \dfrac{\partial f_1}{\partial u_{nu}} & \\
			\vdots & \ddots & \vdots & \\
			\dfrac{\partial f_e}{\partial u_1} & \cdots & \dfrac{\partial f_e}{\partial u_{nu}} &
		\end{bmatrix}, \
	\dfrac{\partial f}{\partial d} =
		\begin{bmatrix}
			\dfrac{\partial f_1}{\partial d_1} & \cdots & \dfrac{\partial f_1}{\partial d_{nd}} & \\
			\vdots & \ddots & \vdots & \\
			\dfrac{\partial f_e}{\partial d_1} & \cdots & \dfrac{\partial f_e}{\partial d_{nd}} &
		\end{bmatrix}
\end{equation}

When the Jacobian matrices are evaluated at the operating point, they in fact become the matrices $ A $, $ B $ and $ B_d  $ of the linear system:

\begin{equation}
	\left. \dfrac{\partial f}{\partial x} \right |_{x_o, u_o, d_o} = A, \;\;\;\;\;\;\;\;\;\;
	\left. \dfrac{\partial f}{\partial u} \right |_{x_o, u_o, d_o} = B, \;\;\;\;\;\;\;\;\;\;
	\left. \dfrac{\partial f}{\partial d} \right |_{x_o, u_o, d_o} = B_d
\end{equation}

The linear model can then be expressed as such:

\begin{equation} \label{eq:state_space_linear}
	\begin{split}
		\dot{x} & = A\bar{x} + B\bar{u} + B_d\bar{d} \\
		\bar{y} & = C\bar{x}
	\end{split}
\end{equation}

with $\bar{x} = x-x_o$, $\bar{u} = u-u_o$, $\bar{d} = d-d_o$ and $\bar{y} = y-y_o$ where $x_o$, $u_o$, $d_o$ and $y_o$ are the linearisation equilibrium operating points of the states and inputs. The implications of this transformation of states will be investigated in section \cref{sec:ctrl}.


%\subsubsection{The Hartman-Grobman theorem} \label{sec:hartman}

Before a Taylor expansion can be performed on the non-linear model \cref{eq:f_noSub}, a linearisation point must be chosen. The Hartman-Grobman theorem states that if the linearisation is performed at a hyperbolic equilibrium, the linear model will effectively describe the dynamical behavior of the system in a near viccinity around the equilibrium point. If this condition is met, the eigenvalues of the linear model will have no real parts equal to zero. This in turn ensures that all manifolds are captured by the linearised dynamics. \\
A manifold in the context of a control system, is the trajectory that a state will follow, when left undisturbed. A stable manifold implies that the state will go to a specific value as time to goes to infinity, and stay there. An unstable manifold implies that opposite: the state will not converge to a fixed point as time goes to infinity. If a manifold is not captured by the linearisation, it means the model does not accurately match the natural behavior of the corresponding state.\\

While the formal definition of the Hartman-Grobman theorem may seem too theoretical to be immediately applicable, it has a simple and appealing takeaway: When linearising a nonlinear system at an equilibrium, check the eigenvalues of the linear model. None of them should have real parts equal or close to zero. If they do, the linear model does not fully describe the system, and if possible linearization should be performed at another equilibrium.


As discussed, linearising at an equilibrium is nessesary, as it removes the offset term from the Taylor expansion. Ideally this point should be a hyperbolic equilibrium. Furthermore, it is natural to linearise at a point where the system is expected to be operating during normal use. \\

The chosen operating point is found using the provided Hi-Fi simulation model. In this simulation of the cooling system, the cargo temperature is controlled to -5$^{\circ}$C. Once the simulation has settled, steady state values for control inputs, disturbances and some states can be directly measured. Not all of the states defined in \cref{eq:xu} are readily available from the simulation, in which case they have been estimated based on other relavant simulation outputs. This method ensures that the linearisation point is an equilibrium as all variables of the simulation have settled.\\


Following the linearisation the following system, input and output matrices are obtained:

\begin{equation}  \label{eq:A_full}
	A =
	\left(\begin{array}{ccccccccccc}
		0 & 0 & \text{1.9828e-04} & 0 & 0 & 0 & 0 & \text{3.8170e-09} & 0 & 0 & 0\\
		0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
		0 & 0 & -0.2440 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
		0 & 0 & 0 & -0.1000 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
		0 & 0 & 0 & 0.6452 & -0.4726 & 0.1702 & -1.1899 & 0 & 0 & 0 & 0\\
		0 & 0 & 0 & -0.3475 & 0.0069 & -0.2684 & -0.3600 & 0 & 0.0953 & 0 & 0\\
		0 & 0 & 0 & 0 & -0.0064 & 0 & -0.0251 & 0 & 0 & 0 & 0\\
		0 & 0 & 0 & 0 & 0.0064 & 0 & 0.0251 & -\text{3.8170e-09} & 0 & 0 & 0\\
		0 & 0 & 0 & -0.2624 & 0.6293 & 0 & 0 & 0 & -2.4729 & 0.0228 & 1.8208\\
		0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & \text{5.6180e-05} & -\text{1.1236e-04} & 0\\
		0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0.0045 & 0 & -0.0045
	\end{array}\right)
\end{equation}

\medskip

\begin{equation}  \label{eq:B_full}
	B = \left(\begin{array}{ccccc}
		-0.0227 & -\text{2.3156e-04} & 0.0021 & 0 & 0\\
		0.0230 & 0 & -0.0020 & 0 & 0\\
		0 & 0 & 0 & -0.0101 & 0\\
		0 & 0 & 0 & 0 & \text{8.3941e-04}\\
		0 & 0 & 0 & 0 & 0\\
		0 & 0 & 0 & 0 & \text{8.3101e-04}\\
		0 & \text{5.0703e-04} & 0 & 0 & 0\\
		\text{5.6955e-07} & 0 & 0 & 0 & 0\\
		0 & 0 & 0 & 0 & 0.0055\\
		0 & 0 & 0 & 0 & 0\\
		0 & 0 & 0 & 0 & 0
	\end{array}\right)
\end{equation}

\medskip

\begin{equation}  \label{eq:C_full}
	C = \left(\begin{array}{ccccccccccc}
		0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0
	\end{array}\right)
\end{equation}

These matrices constitute the linear state space model of the system. The following section will discuss how the model complexity is reduced, allowing for easier controller synthesis. To more easily keep track of the model changes a table is provided for each model iteration. The first of such a table is seen in \cref{tab:model_full}. [A$|$B] Denotes controllability matrix and [A$|$C] denotes observability matrix.

%	Rank of \text{[A$|$C]}


%\centering{\textbf{Model status}}\\


\begin{table}[h]
	\centering
	\caption{Model status: Full model}
	\label{tab:model_full}
	\begin{tabular}{ll}

		\textbf{Linearity status}          & Non-linear   \\ \toprule
		\textbf{Number of states}          & 11           \\
		\textbf{Number of inputs}          & 5            \\
		\textbf{Number of outputs}         & 1            \\ \toprule
		\textbf{Rank of \text{[A$|$B]}}                & 11           \\
		\textbf{Rank of \text{[A$|$C]}}                & 9            \\
		\textbf{Eigenvalues}               & -1 , -2 , -3 \\
		\textbf{A matrix condition number} & 10           \\
	\end{tabular}
\end{table}

\subsubsection{Model Simplifications}
From observing the linearised system matrix \cref{eq:A_full} it is apparent that the first two states ($M_{PJJ}$ and $M_{Con}$) do not affect any states. They are therefore omitted leaving us with smaller dimensions. In practice this means removing the first two rows and columns of A, rows of B and columns of C, yielding \cref{eq:A} \cref{eq:B} \cref{eq:C}

\begin{equation}  \label{eq:A}
	A = \left(\begin{array}{ccccccccc}
		-0.2440 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
		0 & -0.1000 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
		0 & 0.6451 & -0.4720 & 0.1702 & -1.1899 & 0 & 0 & 0 & 0\\
		0 & -0.3474 & 0.0068 & -0.2680 & -0.3600 & 0 & 0.0953 & 0 & 0\\
		0 & 0 & -0.0060 & 0 & -0.0250 & 0 & 0 & 0 & 0\\
		0 & 0 & 0.0060 & 0 & 0.0250 & 0 & 0 & 0 & 0\\
		0 & -0.2624 & 0.6293 & 0 & 0 & 0 & -2.4729 & 0.0228 & 1.8200\\
		0 & 0 & 0 & 0 & 0 & 0 & \text{5.6000e-05} & -\text{1.1200e-04} & 0\\
		0 & 0 & 0 & 0 & 0 & 0 & 0.0045 & 0 & -0.0045
	\end{array}\right)
\end{equation}

\bigskip

\begin{equation}  \label{eq:B}
	B = \left(\begin{array}{ccccc}
		0 & 0 & 0 & -0.0101 & 0\\
		0 & 0 & 0 & 0 & \text{8.3941e-04}\\
		0 & 0 & 0 & 0 & 0\\
		0 & 0 & 0 & 0 & \text{8.3101e-04}\\
		0 & \text{5.0703e-04} & 0 & 0 & 0\\
		\text{5.0000e-07} & 0 & 0 & 0 & 0\\
		0 & 0 & 0 & 0 & 0.0055\\
		0 & 0 & 0 & 0 & 0\\
		0 & 0 & 0 & 0 & 0
	\end{array}\right)
\end{equation}

\medskip

\begin{equation}  \label{eq:C}
	C =\left(\begin{array}{ccccccccc}
		0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0
	\end{array}\right)
\end{equation}


\begin{table}[h]
	\centering
	\caption{Model status: Two first states removed}
	\begin{tabular}{ll}
		\toprule
		\textbf{Linearity status}          & Non-linear   \\ \toprule
		\textbf{Number of states}          & 9           \\
		\textbf{Number of inputs}          & 5            \\
		\textbf{Number of outputs}         & 1            \\ \toprule
		\textbf{Rank of \text{[A$|$B]}}                & 11           \\
		\textbf{Rank of \text{[A$|$C]}}                & 9            \\
		\textbf{Nominal stability}               & \text{$\lambda_i \leq 0, i\in )$} \\
		\textbf{A matrix condition number} & 10           \\ \toprule
	\end{tabular}
\end{table}


\subsubsection{Controllability and observability}
When evaluating a state space system, it is highly relevant to investigate whether the system is controllable and observable. \\
A system is said to be controllable iff there exists a control signal u(t), that can achieve $x(T) = \zeta$, for any $\zeta \in \mathbb{R} ^{n}$, under the constraints $T>0$ and $x(0)=0$. In practice, this means that the actuators are sufficient and able to alter all the states of the system. As a counter example, an uncontrollable system would have at least one state for which there are some values that cannot be reached by the controller.\\
Kalman's test for controllability checks whether the system is controllable. The test is to check whether the controllability matrix which is defined in \cref{eq:ctrb} has full rank.

\begin{equation} \label{eq:ctrb}
	Q_c = [A|B] = \begin{bmatrix}  B & AB & A^2B & \cdots & A^{n-1}B  \end{bmatrix}
\end{equation}

If $Q_c$ does not have full rank, the system is not controllable and action must be taken. This can be in the form of adding the needed actuators or performing a Kalman decomposition, as discussed in the next section.\\

Similarly to controlability, the system observability is highly relevant.

\noindent A system is observable iff $y(t) \equiv 0 \Rightarrow x(t) \equiv 0$. This means that none of the system states can have a non-zero value, if the measured outputs are zero. This guarantees that no dynamical action is happening that cannot be observed by measuring the outputs.\\

Kalman's test for observability is comparable to the test for controlability. The observability matrix is defined.

\begin{equation}
	Q_o = [A|C] = \begin{bmatrix}
		C \\ CA \\ CA^2 \\ \vdots \\ CA^{n-1}
	\end{bmatrix}
\end{equation}

If $Q_o$ does not have full rank, the system is not observable and action must be taken. This can be in the form of adding the needed sensors or performing a Kalman decomposition, as discussed later in section \cref{sec:kalman}


\subsubsection{Condition number} \label{sec:condNumber}
Consider the linear problem $Ax=b$, with $A \in \mathbb{R} ^{n x n}$ and $ x, b \in \mathbb{R} ^{n x 1}$, where x is the unknown solution. The matrix $A$ can be factorized as $A = USV^T$, where:
\begin{center}
	\begin{tabular}{l p{8cm} l}
		$U \in \mathbb{R} ^{n x n}$		& is the matrix of eigenvectors of $AA^H$  &  \\
		$S \in \mathbb{R} ^{n x n}$ 	& is a diagonal matrix of the singular values $\sigma_i$ of $A$ &  \\
		$V \in \mathbb{R} ^{n x n}$		& is the matrix of eigenvectors of $A^HA$  &  \\
	\end{tabular}
\end{center}

The singular values $\sigma$ are each associated with the eigenvectors in $U$ and $V$. $U$ and $V$ form orthonormal bases for the output space (row) and input space (column) of $A$ respectively. The first rowvector contained in $U$ can as such be interpreted as a unit length input vector in a specific direction. Specifically the direction which creates the largest possible output signal. The input is this direction is scaled by the magnitude of the first singular value. The output direction is defined by the first columnvector of $V$. Each subsequent set of vectors and singular value, indicates the gain in other direction. The singular values (gains) are sorted from largest to smallest.

The condition number of a matrix is defined as the ratio between its maximum and minimum singular values. It is a measurement of how sensitive the output $x$ is to a change in the input $b$. In multivariable control theory the condition number is a useful measure in evaluating how tolerant the system is to disturbances and other errors. A large condition number is an indication that small input pertubations might cause large errors in the output signal.\\

It is important to note the intentionally vague term "large condition number". The condition number effectively maps an input error to the corresponding output error. Thus the meaning of a large or small condition number relies on the size of the expected input error and the tolerable output error. In most control applications a condition number of the state transition matrix larger than 10 is considered large, but this is only presented to give intuition of the expected size of the condition number.



\subsubsection{Kalman decomposition} \label{sec:kalman}
If a system with n states is not fully observable, that is $Rank[A|C] = l < n$, it is necessary to perform a decomposition of the system. This is known as a Kalman decomposition, and it separates the system into its observable and unobservable parts. Note, that this is the Kalman decomposition for an unobservable system. There exists a Kalman decomposition for uncontrollable systems as well, but it is not presented here. The Kalman decomposition is in essence a change of basis $z=Px$, which transforms the $A$, $B$, $B_d$ and $C$ matrices of the system:

\begin{equation}
	\begin{split}
		\dot{x} & = Ax + Bu + B_dd \\
		y & = Cx
	\end{split}
\end{equation}

We define $x = P^{-1}z$ and substitute it for x

\begin{equation}
	\begin{split}
		P^{-1}\dot{z} & = AP^{-1}z + Bu + B_dd \\
		y & = CP^{-1}z
	\end{split}
\end{equation}

Isolating $\dot{z}$ yields

\begin{equation}
	\begin{split}
		\dot{z} & = PAP^{-1}z + PBu + PB_dd \\
		y & = CP^{-1}z
	\end{split}
\end{equation}

For the Kalman decomposition, there exists a nonsingular P  $\in \mathbb{R} ^{n x n}$ such that
\begin{equation}
	PAP^{-1} = \begin{bmatrix}
		A_{11}       & 0 \\
		A_{21}       & A_{22} \\
	\end{bmatrix}
\end{equation}

and

\begin{equation}
	CP^{-1} = \begin{bmatrix}
		C_{1}       & 0 \\
	\end{bmatrix}
\end{equation}

where $A_{11} \in \mathbb{R} ^{l x l}$ and $C_{1} \in \mathbb{R} ^{p x l}$, where p is the number of outputs.\\Futhermore the input and disturbance matrices are transformed as such:

\begin{equation}
	PB = \begin{bmatrix}
		B_1 \\
		B_2
	\end{bmatrix}, \
	PB_d = \begin{bmatrix}
		{B_d}_1 \\
		{B_d}_2
	\end{bmatrix}
\end{equation}


The matrices $A_{11}$ and $C_{1}$ constitute an observable subsystem, for which a controller can be designed. This controller will not have information about the state of the unobservable subsystem $A_{22}$. This necessitates that $A_{22}$ has to be internally stable, meaning its eigenvalues has to have negative real parts, resulting in stable behavior when unperturbed.

The matrices $A_{11}$, $B_{1}$ and $C_{1}$ are obtained:

\begin{equation}  \label{eq:A11}
	A_{11} = \left(\begin{array}{ccccccc}
		-0.1000 & 0 & 0 & 0 & 0 & 0 & 0\\
		0.6452 & -0.4726 & 0.1702 & -1.1899 & 0 & 0 & 0\\
		-0.3475 & 0.0069 & -0.2684 & -0.3600 & 0.0953 & 0 & 0\\
		0 & -0.0064 & 0 & -0.0251 & 0 & 0 & 0\\
		-0.2624 & 0.6293 & 0 & 0 & -2.4729 & 0.0228 & 1.8208\\
		0 & 0 & 0 & 0 & \text{5.6180e-05} & -\text{1.1236e-04} & 0\\
		0 & 0 & 0 & 0 & 0.0045 & 0 & -0.0045
	\end{array}\right)
\end{equation}

\bigskip

\begin{equation}  \label{eq:B1}
	B_1 = \left(\begin{array}{ccccc}
		0 & 0 & 0 & 0 & \text{8.3941e-04}\\
		0 & 0 & 0 & 0 & 0\\
		0 & 0 & 0 & 0 & \text{8.3101e-04}\\
		0 & \text{5.0703e-04} & 0 & 0 & 0\\
		0 & 0 & 0 & 0 & 0.0055\\
		0 & 0 & 0 & 0 & 0\\
		0 & 0 & 0 & 0 & 0
	\end{array}\right)
\end{equation}

\todo[inline]{Fjern nulrÃ¦kker}

\medskip

\begin{equation}  \label{eq:C1}
	C_1 =\left(\begin{array}{ccccccc}
		0 & 0 & 0 & 0 & 1 & 0 & 0
	\end{array}\right)
\end{equation}

These matrices define an observable and controllable system model. It is noted that the removal of the unobservable states left the columns 1, 3 and 4 in $B_1$ empty. This means that the 3 corresponding control inputs does not affect the subsystem. Initutively this is not true for the physical system, but for this simplified model, which is accurate around the equilibrium point, they will be held constant.