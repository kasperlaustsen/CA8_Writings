A general state space system is typically defined on the form in \cref{eq:state_space}. It is observed that a change in states over time is defined as a linear combination of vectors and matrices. Having a model on such a state space form is a necessary for state-space controller design.

\begin{equation} \label{eq:state_space}
	\begin{split}
		\dot{\textbf{x}} & = \textbf{A}\textbf{x} + \textbf{B}\textbf{u} + \textbf{B}_d\textbf{d} \\
		\textbf{y} 		& = \textbf{C}\textbf{x}
	\end{split}
\end{equation}

where

\begin{center}
	\begin{tabular}{l p{8cm} l}
		$\textbf{x}$       & State vector                    &  \\
		$\dot{\textbf{x}}$ & Time derivative of state vector &  \\
		$\textbf{y}$       & Output vector                   &  \\
		$\textbf{d}$       & Disturbance vector              &  \\
		$\textbf{A}$       & System matrix                   &  \\
		$\textbf{B}$       & Controllable input matrix       &  \\
		$\textbf{B}_d$     & Disturbance input matrix        &  \\
		$\textbf{C}$       & Output matrix                   &
	\end{tabular}
\end{center}

A prerequisite for making a controller is that the system model used for making the controller is linear. This chapter examines the linearisation of the non-linear model found in \cref{sec:mod}. Linearisation is achieved through a first order Taylor expansion.

Consider some system $\dot{\textbf{x}} = \textbf{f}(\textbf{x},\textbf{u},\textbf{d})$ with \textbf{x} a vector of system states, \textbf{u} a vector of controlled inputs, and \textbf{d} a vector of disturbances. Such a system can be approximated with a first order taylor expansion at an operating point ($\textbf{x}_o, \textbf{u}_o, \textbf{d}_o$) as such:

\begin{equation} \label{eq:taylor}
	\dot{\textbf{x}}   \approx   \textbf{f}(\textbf{x}_o, \textbf{u}_o, \textbf{d}_o)   +
	\left. \dfrac{\partial \textbf{f}}{\partial \textbf{x}} \right |_{\textbf{x}_o, \textbf{u}_o, \textbf{d}_o} \cdot (\textbf{x}-\textbf{x}_0) +
	\left. \dfrac{\partial \textbf{f}}{\partial \textbf{u}} \right |_{\textbf{x}_o, \textbf{u}_o, \textbf{d}_o} \cdot (\textbf{u}-\textbf{u}_0) +
	\left. \dfrac{\partial \textbf{f}}{\partial \textbf{d}} \right |_{\textbf{x}_o, \textbf{u}_o, \textbf{d}_o} \cdot (\textbf{d}-\textbf{d}_0)
\end{equation}

In \cref{eq:taylor} $f(\textbf{x}_o, \textbf{u}_o, \textbf{d}_o) = 0$ because the linearisation is done at an equilibrium point. The partial derivatives can be organized in Jacobian matrices on the form seen in \cref{eq:jacobians} where e is the number of state equations in the non linear system, and n is the number of variables to be differentiated with respect to, (e.g. number of states, inputs and disturbances).

\begin{equation} \label{eq:jacobians}
	\dfrac{\partial \textbf{f}}{\partial \textbf{x}} =
		\begin{bmatrix}
			\dfrac{\partial f_1}{\partial x_1} & \cdots & \dfrac{\partial f_1}{\partial x_n} & \\
			\vdots & \ddots & \vdots & \\
			\dfrac{\partial f_e}{\partial x_1} & \cdots & \dfrac{\partial f_e}{\partial x_n} &
		\end{bmatrix}, \
	\dfrac{\partial \textbf{f}}{\partial \textbf{u}} =
		\begin{bmatrix}
			\dfrac{\partial f_1}{\partial u_1} & \cdots & \dfrac{\partial f_1}{\partial u_n} & \\
			\vdots & \ddots & \vdots & \\
			\dfrac{\partial f_e}{\partial u_1} & \cdots & \dfrac{\partial f_e}{\partial u_n} &
		\end{bmatrix}, \
	\dfrac{\partial \textbf{f}}{\partial \textbf{d}} =
		\begin{bmatrix}
			\dfrac{\partial f_1}{\partial d_1} & \cdots & \dfrac{\partial f_1}{\partial d_n} & \\
			\vdots & \ddots & \vdots & \\
			\dfrac{\partial f_e}{\partial d_1} & \cdots & \dfrac{\partial f_e}{\partial d_n} &
		\end{bmatrix}
\end{equation}

When the Jacobian matrices are evaluated at the operating point, they in fact become the matrices $ \textbf{A} $, $ \textbf{B} $ and $ \textbf{B}_d  $ of the linear system:

\begin{equation}
	\left. \dfrac{\partial \textbf{f}}{\partial \textbf{x}} \right |_{\textbf{x}_o, \textbf{u}_o, \textbf{d}_o} = \textbf{A}, \
	\left. \dfrac{\partial \textbf{f}}{\partial \textbf{u}} \right |_{\textbf{x}_o, \textbf{u}_o, \textbf{d}_o} = \textbf{B}, \
	\left. \dfrac{\partial \textbf{f}}{\partial \textbf{d}} \right |_{\textbf{x}_o, \textbf{u}_o, \textbf{d}_o} = \textbf{B}_d
\end{equation}

The linear model can then be expressed as such:

\begin{equation} \label{eq:state_space_linear}
	\begin{split}
		\dot{x} & = A\bar{x} + B\bar{u} + B_d\bar{d} \\
		\bar{y} & = C\bar{x}
	\end{split}
\end{equation}

with $\bar{x} = x-x_o$, $\bar{u} = u-u_o$, $\bar{d} = d-d_o$ and $\bar{y} = y-y_o$ where $x_o$, $u_o$, $d_o$ and $y_o$ are the linearisation equilibrium operating points of the states and inputs. The implications of this transformation of states will be described in section \cref{sec:ctrl}.\\
\subsubsection{The Hartman-Grobman theorem}

The Hartman-Grobman theorem states that if the linearisation is performed at a hyperbolic equilibrium, the linear model will effectively describe the dynamical behavior of the system in a near viccinity around the equilibrium point. If this condition is met, the eigenvalues of the linear model will have no real parts equal to zero. This in turn ensures that all manifolds are captured by the linearised dynamics. \\
A manifold in the context of a control system, is the trajectory that a state will follow, when left undisturbed. A stable manifold implies that the state will go to a specific value as time to goes to infinity, and stay there. An unstable manifold implies the opposite: the state will follow a trajectory going from a fixed point to infinity as time goes to infinity. If a manifold is not captured by the linearisation, it means the model does not accurately match the natural behavior of the corresponding state.\\

While the formal definition of the Hartman-Grobman theorem may seem too theoretical to be immediately applicable, it has a very simple and rather effective takeaway: When linearising a nonlinear system at an equilibrium, check the eigenvalues of the linear model. None of them should have real parts equal or close to zero. If they do, the linear model does not fully describe the system, and linearization should be performed at another equilibrium.


\subsubsection{Model Simplifications}
To model the behavior of the Hi-Fi simulation model, some simplifications with respect to the real system are made.

\begin{enumerate}
	\item valve is modeled as linear type
	\item coefficient XX is modelled as..
	\item
	\item
	\item
	\item
\end{enumerate}

From observing the system matrix (A) it is apparent that the first two states ($M_{PJJ}$ and $M_{Con}$) do not affect any states except themselves. They are not important with regards to any of the controlled states and are thus simply deleted from the system. In practice this means removing the first two: rows and columns of A, rows of B and columns of C.

When simulating the non-linear system model with inputs held constant at the operating point the state $M_v$ has a constant derivative which makes the state integrate towards infinity. This error is considered as a numeric error \todo[inline]{sikkert ikke sandt sÃ¥ skal sikkert rettes} and a simple fix is used to omit it. The slope of the error is subtracted from the definition of the derivative of the state. It is apparent that the system model does not in any way hold true to the physics of the real system and therefore such a fix which does not make sense in any physical context is considered acceptable.





\subsubsection{Controllability and observability}
When evaluating a state space system, it is highly relevant to investigate wether the system is controllable and observable. \\
A system is said to be controllable iff there exists a control signal u(t), that can achieve $x(T) = \zeta$, for any $\zeta \in \mathbb{R} ^{n}$, under the constraints $T>0$ and $x(0)=0$. In practice, this means that the actuators are sufficient and able to alter all the states of the system. As a counter example, an uncontrollable system would have at least one state, which cannot be driven to \textit{any} value by the controller.\\
Kalman's test for controlability allows for evaluation of the system. The test is to define the controlability matrix of the system:
\begin{equation} 
	Q_c = [A|B] = \begin{bmatrix}
		B & AB & A^2B & \cdots & A^{n-1}B
	\end{bmatrix}
\end{equation}

If $Q_c$ does not have full rank, the system is not controllable and action must be taken. This can be in form of adding the needed actuators or performing a Kalman decomposition, as discussed in the next section.\\

Similarly to controlability, the system observability is highly relevant. A system is observable iff $y(t)=0 \Rightarrow x(t)=0$. This means that non of the states of system can have a non-zero value, if the measured outputs are zero. This guerantees that no dynamical action is happening that cannot be observed by measuring the outputs.\\

Kalman's test for observability is comparable to the test for controlability. The observability matrix is defined.

\begin{equation} 
	Q_o = [A|C] = \begin{bmatrix}
		C \\ CA \\ CA^2 \\ \vdots \\ CA^{n-1}
	\end{bmatrix}
\end{equation}

If $Q_o$ does not have full rank, the system is not observable and action must be taken. This can be in form of adding the needed sensors or performing a Kalman decomposition, as discussed in the next section.\\


\subsubsection{Kalman decomposition}
If a system with n states is not fully observable, that is $Rank[A|C] = l < n$, it is nessesary to perform a decomposition of the system. This is known as a Kalman decomposition, and it seperates the system into its observable and unobservable parts. Note, that this is the Kalman decomposition for an unobservable system. There exists a Kalman decomposition for uncontrollable systems as well, but it is not presented here. The Kalman decomposition is in essence a change of basis $z=Px$, which will in turn transform the A, B, B$_d$ and C matrices of the system:


\begin{equation} 
	\begin{split}
		\dot{x} & = Ax + Bu + B_dd \\
		y & = Cx
	\end{split}
\end{equation}

We define $x = P^{-1}z$ and substitute it for x

\begin{equation} 
	\begin{split}
		P^{-1}\dot{z} & = AP^{-1}z + Bu + B_dd \\
		y & = CP^{-1}z
	\end{split}
\end{equation}

Isolating $\dot{z}$ yields

\begin{equation} 
	\begin{split}
		\dot{z} & = PAP^{-1}z + PBu + PB_dd \\
		y & = CP^{-1}z
	\end{split}
\end{equation}

For the Kalman decomposition, there exists a nonsingular P  $\in \mathbb{R} ^{n x n}$ such that 
\begin{equation} 
	PAP^{-1} = \begin{bmatrix}
		A_{11}       & 0 \\
		A_{21}       & A_{22} \\
	\end{bmatrix}
\end{equation}

and 

\begin{equation} 
	CP^{-1} = \begin{bmatrix}
		C_{1}       & 0 \\
	\end{bmatrix}
\end{equation}

where $A_{11} \in \mathbb{R} ^{l x l}$ and $C_{1} \in \mathbb{R} ^{p x l}$, where p is the number of outputs.\\Futhermore the input and disturbance matrices are transformed as such:

\begin{equation} 
	PB = \begin{bmatrix}
		B_1 \\
		B_2
	\end{bmatrix}, \
	PB_d = \begin{bmatrix}
		{B_d}_1 \\
		{B_d}_2
	\end{bmatrix}
\end{equation}


The matrices $A_{11}$ and $C_{1}$ constitute an observable subsystem, for which a controller can be designed. This controller will not have information about the state of the unobservable subsystem $A_{22}$. This necessitates that $A_{22}$ has to be internally stable, meaning its eigenvalues has to have negative real part, resulting in stable behavior when unperturbed.
