A general state space system is typically defined on the form in \cref{eq:state_space}. It is observed that a change in states over time is defined as a linear combination of vectors and matrices. Having a model on such a state space form is a necessary for state-space controller design.
\todo[inline]{Skriv ovenstÃ¥ende mindre "KLUMSET?!?!?!" :)}

\begin{equation} \label{eq:state_space}
	\begin{split}
		\dot{x} & = Ax + Bu + B_dd \\
		y 		& = Cx
	\end{split}
\end{equation}

where

\begin{center}
	\begin{tabular}{l p{8cm} l}
		$x$       & State vector                    &  \\
		$\dot{x}$ & Time derivative of state vector &  \\
		$y$       & Output vector                   &  \\
		$d$       & Disturbance vector              &  \\
		$A$       & System matrix                   &  \\
		$B$       & Controllable input matrix       &  \\
		$B_d$     & Disturbance input matrix        &  \\
		$C$       & Output matrix                   &
	\end{tabular}
\end{center}

A prerequisite for controller design is that the system model used for making the controller is linear. This chapter examines the linearisation of the non-linear model found in \cref{sec:mod}. Linearisation is achieved through a first order Taylor expansion.

Consider some system $\dot{x} = f(x,u,d)$ with x a vector of system states, u a vector of controlled inputs, and d a vector of disturbances. Such a system can be approximated with a first order taylor expansion at an operating point ($x_o, u_o, d_o$) as such:

\begin{equation} \label{eq:taylor}
	\dot{x}   \approx   f(x_o, u_o, d_o)   +
	\left. \dfrac{\partial f}{\partial x} \right |_{x_o, u_o, d_o} \cdot (x-x_0) +
	\left. \dfrac{\partial f}{\partial u} \right |_{x_o, u_o, d_o} \cdot (u-u_0) +
	\left. \dfrac{\partial f}{\partial d} \right |_{x_o, u_o, d_o} \cdot (d-d_0)
\end{equation}

In \cref{eq:taylor} $f(x_o, u_o, d_o) = 0$ because the linearisation is done at an equilibrium point. The partial derivatives can be organized in Jacobian matrices on the form seen in \cref{eq:jacobians} where e is the number of state equations in the non linear system and nx, nu and nd are the number of states, inputs and disturbances respectively.

\begin{equation} \label{eq:jacobians}
	\dfrac{\partial f}{\partial x} =
		\begin{bmatrix}
			\dfrac{\partial f_1}{\partial x_1} & \cdots & \dfrac{\partial f_1}{\partial x_{nx}} & \\
			\vdots & \ddots & \vdots & \\
			\dfrac{\partial f_e}{\partial x_1} & \cdots & \dfrac{\partial f_e}{\partial x_{nx}} &
		\end{bmatrix}, \
	\dfrac{\partial f}{\partial u} =
		\begin{bmatrix}
			\dfrac{\partial f_1}{\partial u_1} & \cdots & \dfrac{\partial f_1}{\partial u_{nu}} & \\
			\vdots & \ddots & \vdots & \\
			\dfrac{\partial f_e}{\partial u_1} & \cdots & \dfrac{\partial f_e}{\partial u_{nu}} &
		\end{bmatrix}, \
	\dfrac{\partial f}{\partial d} =
		\begin{bmatrix}
			\dfrac{\partial f_1}{\partial d_1} & \cdots & \dfrac{\partial f_1}{\partial d_{nd}} & \\
			\vdots & \ddots & \vdots & \\
			\dfrac{\partial f_e}{\partial d_1} & \cdots & \dfrac{\partial f_e}{\partial d_{nd}} &
		\end{bmatrix}
\end{equation}

When the Jacobian matrices are evaluated at the operating point, they in fact become the matrices $ A $, $ B $ and $ B_d  $ of the linear system:

\begin{equation}
	\left. \dfrac{\partial f}{\partial x} \right |_{x_o, u_o, d_o} = A, \;\;\;\;\;\;\;\;\;\;
	\left. \dfrac{\partial f}{\partial u} \right |_{x_o, u_o, d_o} = B, \;\;\;\;\;\;\;\;\;\;
	\left. \dfrac{\partial f}{\partial d} \right |_{x_o, u_o, d_o} = B_d
\end{equation}

The linear model can then be expressed as such:

\begin{equation} \label{eq:state_space_linear}
	\begin{split}
		\dot{x} & = A\bar{x} + B\bar{u} + B_d\bar{d} \\
		\bar{y} & = C\bar{x}
	\end{split}
\end{equation}

with $\bar{x} = x-x_o$, $\bar{u} = u-u_o$, $\bar{d} = d-d_o$ and $\bar{y} = y-y_o$ where $x_o$, $u_o$, $d_o$ and $y_o$ are the linearisation equilibrium operating points of the states and inputs. The implications of this transformation of states will be investigated in section \cref{sec:ctrl}.\\

Following the linearisation we obtain the following system matrices:

\begin{equation}  \label{eq:A_full}
	A =
	\left(\begin{array}{ccccccccccc}
		0 & 0 & \text{1.9828e-04} & 0 & 0 & 0 & 0 & \text{3.8170e-09} & 0 & 0 & 0\\
		0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
		0 & 0 & -0.2440 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
		0 & 0 & 0 & -0.1000 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
		0 & 0 & 0 & 0.6452 & -0.4726 & 0.1702 & -1.1899 & 0 & 0 & 0 & 0\\
		0 & 0 & 0 & -0.3475 & 0.0069 & -0.2684 & -0.3600 & 0 & 0.0953 & 0 & 0\\
		0 & 0 & 0 & 0 & -0.0064 & 0 & -0.0251 & 0 & 0 & 0 & 0\\
		0 & 0 & 0 & 0 & 0.0064 & 0 & 0.0251 & -\text{3.8170e-09} & 0 & 0 & 0\\
		0 & 0 & 0 & -0.2624 & 0.6293 & 0 & 0 & 0 & -2.4729 & 0.0228 & 1.8208\\
		0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & \text{5.6180e-05} & -\text{1.1236e-04} & 0\\
		0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0.0045 & 0 & -0.0045
	\end{array}\right)
\end{equation}

\begin{equation}  \label{eq:B_full}
	B = \left(\begin{array}{ccccc}
		-0.0227 & -\text{2.3156e-04} & 0.0021 & 0 & 0\\
		0.0230 & 0 & -0.0020 & 0 & 0\\
		0 & 0 & 0 & -0.0101 & 0\\
		0 & 0 & 0 & 0 & \text{8.3941e-04}\\
		0 & 0 & 0 & 0 & 0\\
		0 & 0 & 0 & 0 & \text{8.3101e-04}\\
		0 & \text{5.0703e-04} & 0 & 0 & 0\\
		\text{5.6955e-07} & 0 & 0 & 0 & 0\\
		0 & 0 & 0 & 0 & 0.0055\\
		0 & 0 & 0 & 0 & 0\\
		0 & 0 & 0 & 0 & 0
	\end{array}\right)
\end{equation}

\begin{equation}  \label{eq:C_full}
	C = \left(\begin{array}{ccccccccccc}
		0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0
	\end{array}\right)
\end{equation}



\subsubsection{The Hartman-Grobman theorem}

The Hartman-Grobman theorem states that if the linearisation is performed at a hyperbolic equilibrium, the linear model will effectively describe the dynamical behavior of the system in a near viccinity around the equilibrium point. If this condition is met, the eigenvalues of the linear model will have no real parts equal to zero. This in turn ensures that all manifolds are captured by the linearised dynamics. \\
A manifold in the context of a control system, is the trajectory that a state will follow, when left undisturbed. A stable manifold implies that the state will go to a specific value as time to goes to infinity, and stay there. An unstable manifold implies that opposite: the state will not converge to a fixed point as time goes to infinity. If a manifold is not captured by the linearisation, it means the model does not accurately match the natural behavior of the corresponding state.\\

While the formal definition of the Hartman-Grobman theorem may seem too theoretical to be immediately applicable, it has a very simple and rather effective takeaway: When linearising a nonlinear system at an equilibrium, check the eigenvalues of the linear model. None of them should have real parts equal or close to zero. If they do, the linear model does not fully describe the system, and if possible linearization should be performed at another equilibrium.


\subsubsection{Model Simplifications}
To reduce the complexity of the model and controller synthesis we seek to reduce the number of states.
From observing the linearised system matrix \cref{eq:A_full} it is apparent that the first two states ($M_{PJJ}$ and $M_{Con}$) do not affect any states. They are therefore omitted leaving us with smaller dimensions. In practice this means removing the first two rows and columns of A, rows of B and columns of C, yielding \cref{eq:A} \cref{eq:B} \cref{eq:C}

\begin{equation}  \label{eq:A}
	A = \left(\begin{array}{ccccccccc}
		-0.2440 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
		0 & -0.1000 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
		0 & 0.6451 & -0.4720 & 0.1702 & -1.1899 & 0 & 0 & 0 & 0\\
		0 & -0.3474 & 0.0068 & -0.2680 & -0.3600 & 0 & 0.0953 & 0 & 0\\
		0 & 0 & -0.0060 & 0 & -0.0250 & 0 & 0 & 0 & 0\\
		0 & 0 & 0.0060 & 0 & 0.0250 & 0 & 0 & 0 & 0\\
		0 & -0.2624 & 0.6293 & 0 & 0 & 0 & -2.4729 & 0.0228 & 1.8200\\
		0 & 0 & 0 & 0 & 0 & 0 & \text{5.6000e-05} & -\text{1.1200e-04} & 0\\
		0 & 0 & 0 & 0 & 0 & 0 & 0.0045 & 0 & -0.0045
	\end{array}\right)
\end{equation}

\begin{equation}  \label{eq:B}
	B = \left(\begin{array}{ccccc}
		0 & 0 & 0 & -0.0101 & 0\\
		0 & 0 & 0 & 0 & \text{8.3941e-04}\\
		0 & 0 & 0 & 0 & 0\\
		0 & 0 & 0 & 0 & \text{8.3101e-04}\\
		0 & \text{5.0703e-04} & 0 & 0 & 0\\
		\text{5.0000e-07} & 0 & 0 & 0 & 0\\
		0 & 0 & 0 & 0 & 0.0055\\
		0 & 0 & 0 & 0 & 0\\
		0 & 0 & 0 & 0 & 0
	\end{array}\right)
\end{equation}

\begin{equation}  \label{eq:C}
	C =\left(\begin{array}{ccccccccc}
		0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0
	\end{array}\right)
\end{equation}

When simulating the non-linear system model with inputs held constant at the operating point the state $M_v$ has a constant derivative which makes the state integrate towards infinity. This error is considered as a numeric error. From a physical standpoint it does not make sense for vapor mass to accumulate indefinitely and thus a simple fix is used to omit it. The slope of the error is subtracted from the definition of the derivative of the state.



\subsubsection{Controllability and observability}
When evaluating a state space system, it is highly relevant to investigate whether the system is controllable and observable. \\
A system is said to be controllable iff there exists a control signal u(t), that can achieve $x(T) = \zeta$, for any $\zeta \in \mathbb{R} ^{n}$, under the constraints $T>0$ and $x(0)=0$. In practice, this means that the actuators are sufficient and able to alter all the states of the system. As a counter example, an uncontrollable system would have at least one state for which there are some values that cannot be reached by the controller.\\
Kalman's test for controllability checks whether the system is controllable. The test is to check whether the controllability matrix which is defined in \cref{eq:ctrb} has full rank.

\begin{equation} \label{eq:ctrb}
	Q_c = [A|B] = \begin{bmatrix}  B & AB & A^2B & \cdots & A^{n-1}B  \end{bmatrix}
\end{equation}

If $Q_c$ does not have full rank, the system is not controllable and action must be taken. This can be in form of adding the needed actuators or performing a Kalman decomposition, as discussed in the next section.\\

Similarly to controlability, the system observability is highly relevant.

\noindent A system is observable iff $y(t) \equiv 0 \Rightarrow x(t) \equiv 0$. This means that non of the states of system can have a non-zero value, if the measured outputs are zero. This guerantees that no dynamical action is happening that cannot be observed by measuring the outputs.\\

Kalman's test for observability is comparable to the test for controlability. The observability matrix is defined.

\begin{equation}
	Q_o = [A|C] = \begin{bmatrix}
		C \\ CA \\ CA^2 \\ \vdots \\ CA^{n-1}
	\end{bmatrix}
\end{equation}

If $Q_o$ does not have full rank, the system is not observable and action must be taken. This can be in form of adding the needed sensors or performing a Kalman decomposition, as discussed in the next section.\\


\subsubsection{Kalman decomposition}
\label{sec:kalman}
If a system with n states is not fully observable, that is $Rank[A|C] = l < n$, it is nessesary to perform a decomposition of the system. This is known as a Kalman decomposition, and it seperates the system into its observable and unobservable parts. Note, that this is the Kalman decomposition for an unobservable system. There exists a Kalman decomposition for uncontrollable systems as well, but it is not presented here. The Kalman decomposition is in essence a change of basis $z=Px$, which will in turn transform the A, B, B$_d$ and C matrices of the system:


\begin{equation}
	\begin{split}
		\dot{x} & = Ax + Bu + B_dd \\
		y & = Cx
	\end{split}
\end{equation}

We define $x = P^{-1}z$ and substitute it for x

\begin{equation}
	\begin{split}
		P^{-1}\dot{z} & = AP^{-1}z + Bu + B_dd \\
		y & = CP^{-1}z
	\end{split}
\end{equation}

Isolating $\dot{z}$ yields

\begin{equation}
	\begin{split}
		\dot{z} & = PAP^{-1}z + PBu + PB_dd \\
		y & = CP^{-1}z
	\end{split}
\end{equation}

For the Kalman decomposition, there exists a nonsingular P  $\in \mathbb{R} ^{n x n}$ such that
\begin{equation}
	PAP^{-1} = \begin{bmatrix}
		A_{11}       & 0 \\
		A_{21}       & A_{22} \\
	\end{bmatrix}
\end{equation}

and

\begin{equation}
	CP^{-1} = \begin{bmatrix}
		C_{1}       & 0 \\
	\end{bmatrix}
\end{equation}

where $A_{11} \in \mathbb{R} ^{l x l}$ and $C_{1} \in \mathbb{R} ^{p x l}$, where p is the number of outputs.\\Futhermore the input and disturbance matrices are transformed as such:

\begin{equation}
	PB = \begin{bmatrix}
		B_1 \\
		B_2
	\end{bmatrix}, \
	PB_d = \begin{bmatrix}
		{B_d}_1 \\
		{B_d}_2
	\end{bmatrix}
\end{equation}


The matrices $A_{11}$ and $C_{1}$ constitute an observable subsystem, for which a controller can be designed. This controller will not have information about the state of the unobservable subsystem $A_{22}$. This necessitates that $A_{22}$ has to be internally stable, meaning its eigenvalues has to have negative real part, resulting in stable behavior when unperturbed.

The matrices $A_{11}$, $B_{1}$ and $C_{1}$ are obtained:

\begin{equation}  \label{eq:A11}
	A_{11} = \left(\begin{array}{ccccccc}
		-0.1000 & 0 & 0 & 0 & 0 & 0 & 0\\
		0.6452 & -0.4726 & 0.1702 & -1.1899 & 0 & 0 & 0\\
		-0.3475 & 0.0069 & -0.2684 & -0.3600 & 0.0953 & 0 & 0\\
		0 & -0.0064 & 0 & -0.0251 & 0 & 0 & 0\\
		-0.2624 & 0.6293 & 0 & 0 & -2.4729 & 0.0228 & 1.8208\\
		0 & 0 & 0 & 0 & \text{5.6180e-05} & -\text{1.1236e-04} & 0\\
		0 & 0 & 0 & 0 & 0.0045 & 0 & -0.0045
	\end{array}\right)
\end{equation}

\begin{equation}  \label{eq:B1}
	B_1 = \left(\begin{array}{ccccc}
		0 & 0 & 0 & 0 & \text{8.3941e-04}\\
		0 & 0 & 0 & 0 & 0\\
		0 & 0 & 0 & 0 & \text{8.3101e-04}\\
		0 & \text{5.0703e-04} & 0 & 0 & 0\\
		0 & 0 & 0 & 0 & 0.0055\\
		0 & 0 & 0 & 0 & 0\\
		0 & 0 & 0 & 0 & 0
	\end{array}\right)
\end{equation}

\begin{equation}  \label{eq:C1}
	C_1 =\left(\begin{array}{ccccccc}
		0 & 0 & 0 & 0 & 1 & 0 & 0
	\end{array}\right)
\end{equation}


