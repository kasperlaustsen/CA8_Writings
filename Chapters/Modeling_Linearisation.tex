The model derived in \cref{sec:mod_collec} is non-linear and thus not directly applicable for the control strategy intended for this project. Therefore a linearisation must be performed, where a linear approximation of the model is found at a given operating point. The linear model will approximate the non linear model near the operaing point and thus facilitating the intended linear control strategy. The accuracy of the model is highly dependent on the deviation from the operating points. All these issues will be touched upon in this section, as the linearisation is discussed.

\subsubsection{A Linear State-Space Representation}
A continuous linear state space system is typically defined as seen in \cref{eq:state_space}. The state derivatives are defined as a linear combination of states and inputs, while the outputs are a linear combination of the states. Having a model on such a state space form is a necessary for conventional state-space controller design.

\begin{equation} \label{eq:state_space}
	\begin{split}
		\dot{x} & = Ax + Bu + B_dd \\
		y 		& = Cx
	\end{split}
\end{equation}

where

\begin{center}
	\begin{tabular}{l p{8cm} l}
		$x$       & State vector                    &  \\
		$\dot{x}$ & Time derivative of state vector &  \\
		$y$       & Output vector                   &  \\
		$d$       & Disturbance vector              &  \\
		$A$       & System matrix                   &  \\
		$B$       & Controllable input matrix       &  \\
		$B_d$     & Disturbance input matrix        &  \\
		$C$       & Output matrix                   &
	\end{tabular}
\end{center}

To transform the non-linear model in \cref{eq:f_noSub} to this form, a first order Taylor expansion is used. Performing this method of linearisation will directly output the \textit{A}, \textit{B}, \textit{$B_d$} and \textit{C} matrices of the linear state space representation.

\subsubsection{Linearisation} \label{sec:mod_linearisation}
Consider some non-linear system $\dot{x} = f(x,u,d)$ with $ x $ a vector of system states,$  u $ a vector of controlled inputs, and $ d $ a vector of disturbances. Such a system can be approximated with a first order Taylor expansion at an operating point ($x_o, u_o, d_o$) as such:

\begin{equation} \label{eq:taylor}
	\dot{x}   \approx   f(x_o, u_o, d_o)   +
	\left. \dfrac{\partial f}{\partial x} \right |_{x_o, u_o, d_o} \cdot (x-x_0) +
	\left. \dfrac{\partial f}{\partial u} \right |_{x_o, u_o, d_o} \cdot (u-u_0) +
	\left. \dfrac{\partial f}{\partial d} \right |_{x_o, u_o, d_o} \cdot (d-d_0)
\end{equation}

The linearisation is done at an equilibrium point such that $f(x_o, u_o, d_o) = 0$ in \cref{eq:taylor}. The equilibrium point will now be investigated in greater detail following the Hartman-Grobmann theorem.\\

\textbf{The Hartman-Grobman theorem}\\
Before a Taylor expansion can be performed on the non-linear model \cref{eq:f_noSub}, a linearisation point must be chosen. The Hartman-Grobman theorem states that if the linearisation is performed at a hyperbolic equilibrium, the linear model will effectively describe the dynamical behavior of the system in a near viccinity around the equilibrium point. If this condition is met, the eigenvalues of the linear model will have no real parts equal to zero. This in turn ensures that all manifolds are captured by the linearised dynamics. \\
A manifold in the context of a control system, is the trajectory that a state will follow, when left undisturbed. A stable manifold implies that the state will go to a specific value as time to goes to infinity, and stay there. An unstable manifold implies that opposite: the state will not converge to a fixed point as time goes to infinity. If a manifold is not captured by the linearisation, it means the model does not accurately match the natural behavior of the corresponding state.\\

While the formal definition of the Hartman-Grobman theorem may seem too theoretical to be immediately applicable, it has a simple and appealing takeaway: When linearising a nonlinear system at an equilibrium, check the eigenvalues of the linear model. None of them should have real parts equal or close to zero. If they do, the linear model does not fully describe the system, and if possible linearisation should be performed at another equilibrium.


As discussed, linearising at an equilibrium is nessesary, as it removes the offset term from the Taylor expansion. Ideally this point should be a hyperbolic equilibrium. Furthermore, it is natural to linearise at a point where the system is expected to be operating during normal use. \\

The investigation of the operating point now enables advancing further with the linearisation. The partial derivatives of \cref{eq:taylor} can be organized in Jacobian matrices on the form seen in \cref{eq:jacobians} where e is the number of state equations in the non linear system and nx, nu and nd being the number of states, inputs and disturbances respectively.

\begin{equation} \label{eq:jacobians}
	\dfrac{\partial f}{\partial x} =
	\begin{bmatrix}
		\dfrac{\partial f_1}{\partial x_1} & \cdots & \dfrac{\partial f_1}{\partial x_{nx}} & \\
		\vdots & \ddots & \vdots & \\
		\dfrac{\partial f_e}{\partial x_1} & \cdots & \dfrac{\partial f_e}{\partial x_{nx}} &
	\end{bmatrix}, \
	\dfrac{\partial f}{\partial u} =
	\begin{bmatrix}
		\dfrac{\partial f_1}{\partial u_1} & \cdots & \dfrac{\partial f_1}{\partial u_{nu}} & \\
		\vdots & \ddots & \vdots & \\
		\dfrac{\partial f_e}{\partial u_1} & \cdots & \dfrac{\partial f_e}{\partial u_{nu}} &
	\end{bmatrix}, \
	\dfrac{\partial f}{\partial d} =
	\begin{bmatrix}
		\dfrac{\partial f_1}{\partial d_1} & \cdots & \dfrac{\partial f_1}{\partial d_{nd}} & \\
		\vdots & \ddots & \vdots & \\
		\dfrac{\partial f_e}{\partial d_1} & \cdots & \dfrac{\partial f_e}{\partial d_{nd}} &
	\end{bmatrix}
\end{equation}

When the Jacobian matrices are evaluated at the operating point, they in fact become the matrices $ A $, $ B $ and $ B_d  $ of the linearised system:

\begin{equation}
	\left. \dfrac{\partial f}{\partial x} \right |_{x_o, u_o, d_o} = A, \;\;\;\;\;\;\;\;\;\;
	\left. \dfrac{\partial f}{\partial u} \right |_{x_o, u_o, d_o} = B, \;\;\;\;\;\;\;\;\;\;
	\left. \dfrac{\partial f}{\partial d} \right |_{x_o, u_o, d_o} = B_d
\end{equation}

The linear model can then be expressed as such:

\begin{equation} \label{eq:state_space_linear}
	\begin{split}
		\dot{x} & = A\bar{x} + B\bar{u} + B_d\bar{d} \\
		\bar{y} & = C\bar{x}
	\end{split}
\end{equation}

with $\bar{x} = x-x_o$, $\bar{u} = u-u_o$, $\bar{d} = d-d_o$ and $\bar{y} = y-y_o$ where $x_o$, $u_o$, $d_o$ and $y_o$ are the linearisation equilibrium operating points of the states and inputs. The implications of this transformation of states will be investigated in \cref{sec:ctrl}.

\subsubsection{Linearised Model} \label{sec:linearised-model}
Finding an operating point for a system can be obtained by letting the system settle to a steady state value. The chosen operating point is found using the provided Hi-Fi simulation model. In this simulation of the cooling system, the cargo temperature is controlled to -5$^{\circ}$C. Once the simulation has settled, steady state values for control inputs, disturbances and some states can be directly measured. Not all of the states defined in \cref{eq:xu} are readily available from the simulation, in which case they have been estimated based on other relavant simulation outputs. This method tries to ensure that the linearisation point is an equilibrium as all variables of the simulation have settled. The values can be seen in the tables in the bottom of  \cref{sec:non_lin_model}. Furthermore steady-state values were used for all table look-ups as another simplification.\\

Linearising the non-linear system without the faulty states $ M_{pjj} $ $ M_{con} $ as described in \cref{sec:model-verification} yields the following system matrices with 10 states.

\begin{equation}  \label{eq:A_full}
	A =
	\left(\begin{array}{cccccccccc}
		-0.2642 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
		0 & -0.1000 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
		0 & 0.8417 & -0.6085 & 0.3062 & -2.7922 & 0 & 0 & 0 & 0 & 0\\
		0 & -0.2370 & 0.0057 & -0.2643 & -0.2190 & 0 & 0.0924 & 0 & 0 & 0\\
		0 & 0 & -0.0041 & 0 & -0.0381 & 0 & 0 & 0 & 0 & 0\\
		0 & 0 & 0.0041 & 0 & 0.0381 & 0 & 0 & 0 & 0 & 0\\
		0 & -0.0030 & 0.0085 & 0 & 0 & 0 & -0.0298 & \text{2.6253e-04} & 0.0210 & 0\\
		0 & 0 & 0 & 0 & 0 & 0 & \text{5.6180e-05} & -\text{1.1236e-04} & 0 & 0\\
		0 & 0 & 0 & 0 & 0 & 0 & 0.0045 & 0 & -0.0045 & 0\\
		0 & 0 & \text{6.6083e-04} & 0.0015 & 0.0081 & 0 & 0 & 0 & 0 & -0.0100
	\end{array}\right)
\end{equation}

%\begin{equation}  \label{eq:A_full}
%	A =
%	\kbordermatrix{
	%		&  T_m	& \dot{m}_{air}	& T_{mlv}	&T_{mv}	&M_{lv}	&M_v	&T_{air} &T_{box}	&T_{cargo}	&T_v \\
	%		T_m				& -0.2642 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
	%		\dot{m}_{air}	& 0 & -0.1000 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
	%		T_{mlv}			& 0 & 0.8417 & -0.6085 & 0.3062 & -2.7922 & 0 & 0 & 0 & 0 & 0\\
	%		T_{mv}			& 0 & -0.2370 & 0.0057 & -0.2643 & -0.2190 & 0 & 0.0924 & 0 & 0 & 0\\
	%		M_{lv}			& 0 & 0 & -0.0041 & 0 & -0.0381 & 0 & 0 & 0 & 0 & 0\\
	%		M_v 			& 0 & 0 & 0.0041 & 0 & 0.0381 & 0 & 0 & 0 & 0 & 0\\
	%		T_{air} 		& 0 & -0.0030 & 0.0085 & 0 & 0 & 0 & -0.0298 & \text{2.6253e-04} & 0.0210 & 0\\
	%		T_{box}			& 0 & 0 & 0 & 0 & 0 & 0 & \text{5.6180e-05} & -\text{1.1236e-04} & 0 & 0\\
	%		T_{cargo }		& 0 & 0 & 0 & 0 & 0 & 0 & 0.0045 & 0 & -0.0045 & 0\\
	%		T_v 			& 0 & 0 & \text{6.6083e-04} & 0.0015 & 0.0081 & 0 & 0 & 0 & 0 & -0.0100
	%				}
%\end{equation}

\medskip
As seen in \cref{eq:B_full} the columns 1 and 3 (corresponding to $ \omega $ and $ \Theta_2 $) are only zeros and it is thus only 3 of the inputs that actually map to the states. Therefore we are left with 3 inputs in stead of 5, hence the dimension of $ B $ end up as $ (10 \times 3) $ as in \cref{eq:B_redu}.
\begin{align}
	B = &\kbordermatrix{
		& \omega & \Theta_1 & \Theta_2 & U_{fan1} & U_{fan2} \\
		T_m 			& 0 & 0 & 0 & -0.0093 & 0\\
		\dot{m}_{air}	& 0 & 0 & 0 & 0 & \text{7.9630e-04}\\
		T_{mlv}			& 0 & 0 & 0 & 0 & 0\\
		T_{mv}			& 0 & 0 & 0 & 0 & 0.0011\\
		M_{lv}			& 0 & \text{5.0703e-04} & 0 & 0 & 0\\
		M_v 			& 0 & 0 & 0 & 0 & 0\\
		T_{air}  		& 0 & 0 & 0 & 0 & \text{1.0069e-04}\\
		T_{box}	 		& 0 & 0 & 0 & 0 & 0\\
		T_{cargo} 		& 0 & 0 & 0 & 0 & 0\\
		T_v 			& 0 & 0 & 0 & 0 & 0
	} \label{eq:B_full}	\\
	\Downarrow \nonumber \\
	B = &\kbordermatrix{
		& \Theta_1  & U_{fan1} & U_{fan2} \\
		T_m 			& 0 					& -0.0093 	& 0\\
		\dot{m}_{air}	& 0 					& 0 		& \text{7.9630e-04}\\
		T_{mlv}			& 0 					& 0 		& 0\\
		T_{mv}			& 0 					& 0 		& 0.0011\\
		M_{lv}			& \text{5.0703e-04} 	& 0 		& 0\\
		M_v 			& 0 					& 0 		& 0\\
		T_{air}  		& 0 					& 0 		& \text{1.0069e-04}\\
		T_{box}	 		& 0 					& 0 		& 0\\
		T_{cargo} 		& 0 					& 0 		& 0\\
		T_v 			& 0 					& 0 		& 0
	} \label{eq:B_redu}
\end{align}

\medskip

\begin{equation}  \label{eq:Bd_full}
	B_d = \left(\begin{array}{c}
		0.0955\\
		0\\
		0\\
		0\\
		0\\
		0\\
		0\\
		\text{5.6180e-05}\\
		0\\
		0
	\end{array}\right)
\end{equation}

\begin{equation}  \label{eq:C_full}
	C = \left(\begin{array}{ccccccccccc}
		0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 \\
		0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1
	\end{array}\right)
\end{equation}

These matrices constitute the linear state space model of the system. The system is stable as the eigenvalues of $A$, which are the poles of the system, are all negative. Alarmingly the real part of one pole is 1.3e-9 which is so numerically small that it can be considered zero. The implications of this were investigated in \cref{sec:mod_linearisation} in the Hartman-Grobman theorem section. It means that some part of the linearised model does not correctly depict the behavior of the system at the chosen operating point. \\

The fact that changes in the compressor speed and condenser throttle valve opening degree do not affect the system is not expected when considering the physical system. The flow of refrigerant is driven by the compressor and the equivalent flow resistance in the refrigeration system. The condenser throttle valve is indeed a significant part of this overall resistance. The flow of refrigerant decides cooling capacity. Therefore it is surprising that the two mentioned inputs do not affect the states. However as also touched upon in \cref{sec:mod_collec}, several components do not connect. As a result two of the states in the system are integrating as was seen in \cref{fig:non_lin_sim_faulty_Mass} which might lend some explanation to why some inputs do not map to the states as expected. The flows entering and leaving the condenser are not coupled, as the output pressure of the condenser is defined as a steady state value, signified by the red color of $ p_3 $ in \cref{fig:Block_diagram_inout}. This means that as the mass inside the condenser is integrating up, the pressure should increase as a result, but it does not. If the pressure would increase, the condenser throttle valve would yield a higher flow that would ensure coupling between the flows in and out of the condenser.

As a consequence of the flows in and out of the condenser not being coupled, the compressor flow does not affect flows into the evaporator. This can explain why the compressor does not affect the states of the system. In terms of $ \Theta_2 $, again referring to \cref{fig:Block_diagram_inout}, it is seen that the flow leaving the expansion valve is not affected by the flash tank, as the flash tank receives a flow from the expansion valve. This means that the flow into the flash tank from the condenser throttle valve is not affecting the flow in the expansion valve and hence the flow into the evaporator.

The reason for the great focus on the evaporator in this regard is that 6 of the states reside in the evaporator. Additionally the only interface between the box and the refrigeration system is through the evaporator.

Furthermore as mentioned earlier all values which were supposed to be found from lookup tables were substituted with steady state values from the Hi-Fi simulation. This could potentially also be factor with regards to the reduced mapping between components.\\

The obtained linear model is now used to investigate details about the system, such as the controllability and observability of the system.


\subsubsection{Controllability and observability}
When evaluating a state space system, it is highly relevant to investigate whether the system is controllable and observable. \\
A system is said to be controllable iff there exists a control signal u(t), that can achieve $x(T) = \zeta$, for any $\zeta \in \mathbb{R} ^{n}$, under the constraints $T>0$ and $x(0)=0$. In practice, this means that the actuators are sufficient and able to alter all the states of the system. As a counter example, an uncontrollable system would have at least one state for which there are some values that cannot be reached by the controller.\\
Kalman's test for controllability checks whether the system is controllable. The test is to check whether the controllability matrix which is defined in \cref{eq:ctrb} has full rank.

\begin{equation} \label{eq:ctrb}
	Q_c = [A|B] = \begin{bmatrix}  B & AB & A^2B & \cdots & A^{n-1}B  \end{bmatrix}
\end{equation}

If $Q_c$ does not have full rank, the system is not controllable and action must be taken. This can be in the form of adding the needed actuators or performing a Kalman Decomposition. For the system at hand $ rank(Q_c) = 10 $. This indicates that the system is controllable.\\

Similarly to controllability, the system can be checked for observability. Observability determines whether all states in a system can be estimated with an observer based on the available outputs.

\noindent A system is observable iff $y(t) \equiv 0 \Rightarrow x(t) \equiv 0$. This means that none of the system states can have a non-zero value, if the measured outputs are zero. This guarantees that no dynamical action is happening that cannot be observed by measuring the outputs.\\

Kalman's test for observability is comparable to the test for controllability. The observability matrix is defined.

\begin{equation}
	Q_o = [A|C] = \begin{bmatrix}
		C \\ CA \\ CA^2 \\ \vdots \\ CA^{n-1}
	\end{bmatrix}
\end{equation}

If $Q_o$ does not have full rank, the system is not observable and action must be taken. This can be in the form of adding the needed sensors or performing a Kalman decomposition, as discussed later in section \cref{sec:kalman}
For the system at hand $ rank(Q_o) = 8 $. This means that some system states can not be observed from the available outputs. When consulting \cref{eq:f_noSub} it can be observed that the states $T_m$ and $M_v$ do not affect the output states $T_{air}$ and $T_v$. Intuitively the evaporator refrigerant vapor mass affects the vapor temperature. In the appendix in \cref{sec:app:evap_addition} an attempt is made at deriving a full expression for the evaporator vapor temperature. In the resulting full state expression in \cref{eq:app:dTvstate} it can also be observed that the $M_v$ state has an impact which further confirms the intuition. The project group did not succeed in implementing the state and thus the "rigged" state defined in \cref{sec:evaporator}.

As a result of $T_m$ and $M_v$ not being observable action must be taken to remove them and thus the Kalman decomposition is introduced.

\subsubsection{Kalman decomposition for unobservable system} \label{sec:kalman}
If a system with n states is not fully observable, that is $Rank[A|C] = l < n$, it is necessary to perform a decomposition of the system. This is known as a Kalman decomposition, and it separates the system into its observable and unobservable parts. Note, that this is the Kalman decomposition for an unobservable system. There exists a Kalman decomposition for uncontrollable systems as well, but it is not presented here. The Kalman decomposition is in essence a change of basis $z=Px$, which transforms the $A$, $B$, $B_d$ and $C$ matrices of the linear system:

\begin{equation}
	\begin{split}
		\dot{x} & = Ax + Bu + B_dd \\
		y & = Cx
	\end{split}
\end{equation}

Now defining $x = P^{-1}z$ and substituting it for x

\begin{equation}
	\begin{split}
		P^{-1}\dot{z} & = AP^{-1}z + Bu + B_dd \\
		y & = CP^{-1}z
	\end{split}
\end{equation}

Isolating $\dot{z}$ yields

\begin{equation}
	\begin{split}
		\dot{z} & = PAP^{-1}z + PBu + PB_dd \\
		y & = CP^{-1}z
	\end{split}
\end{equation}

For the Kalman decomposition, there exists a nonsingular P  $\in \mathbb{R} ^{n x n}$ such that
\begin{equation}
	PAP^{-1} = \begin{bmatrix}
		A_{11}       & 0 \\
		A_{21}       & A_{22} \\
	\end{bmatrix}
\end{equation}

and

\begin{equation}
	CP^{-1} = \begin{bmatrix}
		C_{1}       & 0 \\
	\end{bmatrix}
\end{equation}

where $A_{11} \in \mathbb{R} ^{l x l}$ and $C_{1} \in \mathbb{R} ^{p x l}$, where p is the number of outputs.\\Futhermore the input and disturbance matrices are transformed as such:

\begin{equation}
	PB = \begin{bmatrix}
		B_1 \\
		B_2
	\end{bmatrix}, \
	PB_d = \begin{bmatrix}
		{B_d}_1 \\
		{B_d}_2
	\end{bmatrix}
\end{equation}


The matrices $A_{11}$ and $C_{1}$ constitute an observable subsystem, for which an observer based controller can be designed. This controller will not have information about the state of the unobservable subsystem $A_{22}$. This necessitates that $A_{22}$ has to be internally stable, meaning its eigenvalues has to have negative real parts, resulting in stable behavior when unperturbed.

Performing the Kalman Decomposition yields the observable subsystem given below, where the states unobservable states $ T_m $ and $ M_v $ are removed.

\begin{equation}  \label{eq:A11}
	A_{11} = \left(\begin{array}{cccccccc}
		-0.1000 &        0 &        0 &        0 &        0 &        0 &        0 &        0  \\
		0.8417 &  -0.6085 &   0.3062 &  -2.7922 &        0 &        0 &        0 &        0  \\
		-0.2370 &   0.0057 &  -0.2643 &  -0.2190 &   0.0924 &        0 &        0 &        0  \\
		0 &  -0.0041 &        0 &  -0.0381 &        0 &        0 &        0 &        0  \\
		-0.0030 &   0.0085 &        0 &        0 &  -0.0298 &   0.0003 &   0.0210 &        0  \\
		0 &        0 &        0 &        0 &   0.0001 &  -0.0001 &        0 &        0  \\
		0 &        0 &        0 &        0 &   0.0045 &        0 &  -0.0045 &        0  \\
		0 &   0.0007 &   0.0015 &   0.0081 &        0 &        0 &        0 &  -0.0100
	\end{array}\right)
\end{equation}

\bigskip

%\begin{equation}  \label{eq:B1}
%	B_1 = \left(\begin{array}{ccccc}
	%		0 & 0 & 0 & 0 & 0.00083\\
	%		0 & 0 & 0 & 0 & 0\\
	%		0 & 0 & 0 & 0 & 0.0011\\
	%		0 & 0.0005 & 0 & 0 & 0\\
	%		0 & 0 & 0 & 0 & 0.0001\\
	%		0 & 0 & 0 & 0 & 0\\
	%		0 & 0 & 0 & 0 & 0\\
	%		0 & 0 & 0 & 0 & 0
	%	\end{array}\right)
%\end{equation}

As was the case with the B matrix of the linear system in \cref{eq:B_full}, the kalman decomposition reduced system also has zero columns as seen in \cref{eq:B1}. $ \Theta_1 $ and $ U_{fan2} $ are now the only inputs being mapped to the states and such the resulting $ B_1 $ matrix only includes two rows as observed in \cref{eq:B1_redu}.
\begin{align}
	B_1 & = \kbordermatrix{
		& \omega & \Theta_1 & \Theta_2 & U_{fan1} & U_{fan2} \\
		\dot{m}_{air}	& 0 & 0 & 0 & 0 & 0.00083\\
		T_{mlv}			& 0 & 0 & 0 & 0 & 0\\
		T_{mv}			& 0 & 0 & 0 & 0 & 0.0011\\
		M_{lv}			& 0 & 0.0005 & 0 & 0 & 0\\
		T_{air}  		& 0 & 0 & 0 & 0 & 0.0001\\
		T_{box}	 		& 0 & 0 & 0 & 0 & 0\\
		T_{cargo} 		& 0 & 0 & 0 & 0 & 0\\
		T_v 			& 0 & 0 & 0 & 0 & 0
	} \label{eq:B1} \\
	& \Downarrow \nonumber\\
	B_1	& = \kbordermatrix{
		& \Theta_1 &  U_{fan2} \\
		\dot{m}_{air}	& 0 		& 0.00083\\
		T_{mlv}			& 0 		& 0\\
		T_{mv}			& 0 		& 0.0011\\
		M_{lv}			& 0.0005	& 0\\
		T_{air}  		& 0 		& 0.0001\\
		T_{box}	 		& 0 		& 0\\
		T_{cargo} 		& 0 		& 0\\
		T_v 			& 0 		& 0
	} \label{eq:B1_redu}
\end{align}

\begin{equation}  \label{eq:Bd}
	B_{d1} = \left(\begin{array}{c}
		0\\
		0\\
		0\\
		0\\
		0\\
		\text{5.6180e-05}\\
		0\\
		0
	\end{array}\right)
\end{equation}


%\begin{equation}  \label{eq:B1}
%	B_1 = \kbordermatrix{
	%		& \omega & \Theta_1 & \Theta_2 & U_{fan1} & U_{fan2} \\
	%		\dot{m}_{air}	& 0 & 0 & 0 & 0 & 0.00083\\
	%		T_{mlv}			& 0 & 0 & 0 & 0 & 0\\
	%		T_{mv}			& 0 & 0 & 0 & 0 & 0.0011\\
	%		M_{lv}			& 0 & 0.0005 & 0 & 0 & 0\\
	%		T_{air}  		& 0 & 0 & 0 & 0 & 0.0001\\
	%		T_{box}	 		& 0 & 0 & 0 & 0 & 0\\
	%		T_{cargo} 		& 0 & 0 & 0 & 0 & 0\\
	%		T_v 			& 0 & 0 & 0 & 0 & 0
	%	}
%\end{equation}
%\begin{equation*}
%	\Downarrow
%\end{equation*}
%
%\begin{equation} \label{eq:B1_redu}
%	B_1	=
%	\kbordermatrix{
	%		& \Theta_1 &  U_{fan2} \\
	%		\dot{m}_{air}	& 0 		& 0.00083\\
	%		T_{mlv}			& 0 		& 0\\
	%		T_{mv}			& 0 		& 0.0011\\
	%		M_{lv}			& 0.0005	& 0\\
	%		T_{air}  		& 0 		& 0.0001\\
	%		T_{box}	 		& 0 		& 0\\
	%		T_{cargo} 		& 0 		& 0\\
	%		T_v 			& 0 		& 0
	%	}
%\end{equation}

\medskip

\begin{equation}  \label{eq:C1}
	C_1 =\left(\begin{array}{cccccccc}
		0 &    0 &    0 &    0 &    1 &    0 &    0 &    0 \\
		0 &    0 &    0 &    0 &    0 &    0 &    0 &    1
	\end{array}\right)
\end{equation}

These matrices define an observable and controllable system model. It is noted that the removal of the unobservable states left an extra zero column in $B_1$ compared to $ B $ \cref{eq:B_full}. The input that 'disappears' during the Kalman Decomposition is $ U_{fan1} $ which affects the condenser. Since the metal temperature state in the condenser $ T_m $ is part of the unobservable subsystem, it makes sense that the fan speed to the condenser does not map to the observable states.
In the end means that the 3 corresponding control inputs does not affect the observable subsystem. Intuitively this is not true for the physical system, but it is none the less the case for this simplified model, which is accurate around the equilibrium point.\\

As expected the kalman decomposition reduced system is stable as all eigenvalues of the $A_{11}$ matrix are negative. As mentioned in \cref{sec:linearised-model}, $A$ of the linearised model contained an eigenvalue numerically close to zero that it is considered zero. This eigenvalue has disappeared in the Kalman decomposition, leaving the biggest pole location at -1.09e-04.


\subsubsection{Condition number} \label{sec:condNumber}
As a supplement to whether the system is controllable and observable, which is a binary decision, the condition number is introduced. The condition number can bring in nuances as to the degree of how controllable or observable a system is. Before discussing the condition number it is necessary to first touch on the term "singular value", by introducing the Singular Value Decomposition (SVD).\\

Consider the linear problem $Ax=b$, with $A \in \mathbb{R} ^{n x n}$ and $ x, b \in \mathbb{R} ^{n x 1}$, where x is the unknown solution. The matrix $A$ can be factorized by SVD as $A = USV^T$, where:
\begin{center}
	\begin{tabular}{l p{8cm} l}
		$U \in \mathbb{R} ^{n x n}$		& is the matrix of eigenvectors of $AA^H$  &  \\
		$S \in \mathbb{R} ^{n x n}$ 	& is a diagonal matrix of the singular values $\sigma_i$ of $A$ &  \\
		$V \in \mathbb{R} ^{n x n}$		& is the matrix of eigenvectors of $A^HA$  &  \\
	\end{tabular}
\end{center}

The singular values $\sigma$ are each associated with the eigenvectors in $U$ and $V$. $U$ and $V$ form orthonormal bases for the output space (row) and input space (column) of $A$ respectively. The first row vector contained in $U$ can as such be interpreted as a unit length input vector in a specific direction. Specifically the direction which creates the largest possible output signal. The input is this direction is scaled by the magnitude of the first singular value. The output direction is defined by the first columnvector of $V$. Each subsequent set of vectors and singular value, indicates the gain in a direction. The singular values (gains) are sorted from largest to smallest.

The condition number of a matrix is defined as the ratio between its largest and smallest singular values. It is a measurement of how sensitive the output $x$ is to a change in the input $b$. In multivariable control theory the condition number is a useful measure in evaluating how tolerant the system is to disturbances and other errors. A large condition number is an indication that small input pertubations might cause large errors in the output signal.\\

It is important to note the intentionally vague term "large condition number". The condition number effectively maps an input error to the corresponding output error. Thus the meaning of a large or small condition number relies on the size of the expected input error and the tolerable output error. In some control applications a condition number of $A$ larger than 10 is considered large. This would be the case for a system where all states are largely inside same numerical range. This is not the case for this refrigeration model where states vary greatly in size from $M_v$ at around 0.001 \si{kg} to almost any temperature state around 250-300 \si{K}. Furthermore the numerical size differences between variables with different SI units also has an impact. A common pressure such as the atmospherical pressure lies at 100000 [Pa].

The condition number for the controllability matrix is 1.195e+09 for the linearised model without the $M_{Con}$ and $M_{PJJ}$ states and 2.934e+08 for the Kalman decomposition reduced model. Evaluating whether these condition numbers are alarming in this case becomes a difficult task. It is surely worth keeping the seemingly high condition numbers in mind when evaluating system behavior, and when further developing and testing the model.


\subsubsection{Model info, wrap up}
\begin{tabular}{ccc}
	\begin{minipage}{.5\linewidth}
		%		\begin{table}[h]
			\centering
			%			\caption{Linearised model from \cref{sec:linearised-model}}
			\label{tab:model_full}
			\begin{tabular}{ll}
				\toprule
				\textbf{Linearised system from \cref{sec:linearised-model}} &  \\ \toprule
				\textbf{Number of states}                                   & 10        \\
				\textbf{Number of inputs}                                   & 3         \\
				\textbf{Number of outputs}                                  & 2         \\ \toprule
				\textbf{Rank of \text{[A$|$B]}}                             & 10        \\
				\textbf{Rank of \text{[A$|$C]}}                             & 8         \\
				\textbf{Eigenvalues}                                        & $ _i < 0 $ \\
				\textbf{Condition number of A}                              & 3.165e+09 \\
				\textbf{Condition number of \text{[A$|$B]}}                 & 1.195e+09 \\
				\textbf{Condition number of \text{[A$|$C]}}                 & $\infty$
			\end{tabular}
			%		\end{table}
	\end{minipage}
	\begin{minipage}{.5\linewidth}
		%		\begin{table}[h]
			\centering
			%			\caption{Kalman decomposed model}
			\begin{tabular}{ll}
				\toprule
				\textbf{Kalman decomposed model from \cref{sec:kalman}} &  \\ \toprule
				\textbf{Number of states}                               & 8         \\
				\textbf{Number of inputs}                               & 2         \\
				\textbf{Number of outputs}                              & 2         \\ \toprule
				\textbf{Rank of \text{[A$|$B]}}                         & 8         \\
				\textbf{Rank of \text{[A$|$C]}}                         & 8         \\
				\textbf{Eigenvalues}                                    &  $ _i < 0 $ \\
				\textbf{Condition number of A}                          & 2.747e+04 \\
				\textbf{Condition number of \text{[A$|$B]}}             & 2.934e+08 \\
				\textbf{Condition number of \text{[A$|$C]}}             & 4.411e+06
			\end{tabular}
			%		\end{table}
	\end{minipage}

\end{tabular}